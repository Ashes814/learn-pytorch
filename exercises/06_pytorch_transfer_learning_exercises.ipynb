{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/06_pytorch_transfer_learning_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNqPNlYylluR"
      },
      "source": [
        "# 06. PyTorch Transfer Learning Exercises\n",
        "\n",
        "Welcome to the 06. PyTorch Transfer Learning exercise template notebook.\n",
        "\n",
        "There are several questions in this notebook and it's your goal to answer them by writing Python and PyTorch code.\n",
        "\n",
        "> **Note:** There may be more than one solution to each of the exercises, don't worry too much about the *exact* right answer. Try to write some code that works first and then improve it if you can.\n",
        "\n",
        "## Resources and solutions\n",
        "\n",
        "* These exercises/solutions are based on [section 06. PyTorch Transfer Learning](https://www.learnpytorch.io/06_pytorch_transfer_learning/) of the Learn PyTorch for Deep Learning course by Zero to Mastery.\n",
        "\n",
        "**Solutions:** \n",
        "\n",
        "Try to complete the code below *before* looking at these.\n",
        "\n",
        "* See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/ueLolShyFqs).\n",
        "* See an example [solutions notebook for these exercises on GitHub](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/06_pytorch_transfer_learning_exercise_solutions.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwmoMhW8IqSu"
      },
      "source": [
        "## 1. Make predictions on the entire test dataset and plot a confusion matrix for the results of our model compared to the truth labels. \n",
        "* **Note:** You will need to get the dataset and the trained model/retrain the model from notebook 06 to perform predictions.\n",
        "* Check out [03. PyTorch Computer Vision section 10](https://www.learnpytorch.io/03_pytorch_computer_vision/#10-making-a-confusion-matrix-for-further-prediction-evaluation) for ideas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqtAWBUJgaF1",
        "outputId": "14cc75f3-e109-4e84-c941-2598df3557b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4056, done.\u001b[K\n",
            "remote: Counting objects: 100% (4056/4056), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1626/1626), done.\u001b[K\n",
            "remote: Total 4056 (delta 2387), reused 3946 (delta 2369), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (4056/4056), 649.87 MiB | 11.16 MiB/s, done.\n",
            "Resolving deltas: 100% (2387/2387), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries/code\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O10_T_xSKJlf",
        "outputId": "fd30e756-e542-4b2b-d974-1ed38451fecf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'mps'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrzg3TaSKLAh"
      },
      "source": [
        "### Get data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt_CNQ4rKPmg",
        "outputId": "a1364d91-3afa-4401-94cb-94e4df837f06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Did not find data/pizza_steak_sushi directory, creating one...\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it... \n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi data...\") \n",
        "        zip_ref.extractall(image_path)\n",
        "\n",
        "    # Remove .zip file\n",
        "    os.remove(data_path / \"pizza_steak_sushi.zip\")\n",
        "\n",
        "# Setup Dirs\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGaMWWaoKQlM"
      },
      "source": [
        "### Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VNIQNEQVKVXu"
      },
      "outputs": [],
      "source": [
        "# Create a transforms pipeline\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njd5lHTcKW23",
        "outputId": "fbc224df-8243-4e7b-90cd-49adc000fd47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x14f0c8090>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x14f025b10>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create training and testing DataLoader's as well as get a list of class names\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=simple_transform, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                               batch_size=32) # set mini-batch size to 32\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ciw2DiRHKaSE"
      },
      "source": [
        "### Get and prepare a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "6e25b4bb0d254191a793696a0f4f00ce",
            "37424313e66f474da42cfe1b512f09df",
            "58fd00f6a9114192a4fa757c1f669bff",
            "f115ea4b5fad4bb1910fca49ed3da8a1",
            "e8eba8e353e940ff9287929e41e4d656",
            "bc33539914a947ee89c271f10ea6a2bb",
            "6e03cb60fab94b7e92ce16c8178922dd",
            "5d464254c31d4516899643112fa0e958",
            "06df3ad4b7454556a43b6d61640b12f8",
            "0bdc7325c839439589a16c88876d6bd5",
            "873a483782894789bf0dee546a1b2d50"
          ]
        },
        "id": "snUuRXd8Kdk5",
        "outputId": "eac2a1e6-5607-437e-90b5-41639d17e5a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/zowcool/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Users/zowcool/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Setup the model with pretrained weights and send it to the target device \n",
        "model_0 = torchvision.models.efficientnet_b0(pretrained=True).to(device)\n",
        "#model_0 # uncomment to output (it's very long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IbRhGvy_KeVL"
      },
      "outputs": [],
      "source": [
        "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
        "for param in model_0.features.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "G1-6xV3ZKeSX"
      },
      "outputs": [],
      "source": [
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Get the length of class_names (one output unit for each class)\n",
        "output_shape = len(class_names)\n",
        "\n",
        "# Recreate the classifier layer and seed it to the target device\n",
        "model_0.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True), \n",
        "    torch.nn.Linear(in_features=1280, \n",
        "                    out_features=output_shape, # same number of output units as our number of classes\n",
        "                    bias=True)).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQFaXX8CKePi"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "exxU79eaKeM6"
      },
      "outputs": [],
      "source": [
        "# Define loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_0.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "ae21171f17de45d895ab7a319dade609",
            "f9c60d9c0aed49faa993fd865fb09174",
            "755366e3f75e44c2b7a79bce78d77d11",
            "4a05e8d965124327a2329cf9e1eec984",
            "fe93ec079b384ac38a6f4d0e505431ff",
            "88dea77f1bcf44ffb69654515ee34f54",
            "2678a567b0414e1d9cfbfc2ecf5ffd30",
            "ce621be138a84f33b24c05b2d9cfd5f0",
            "1fa41d239a3a4845904434d057476a75",
            "f4827c6e36a1463fb0c82347f64230a2",
            "cea8f9c48bd8429998352a090173f537"
          ]
        },
        "id": "ComVkVtuKeKG",
        "outputId": "6d43205a-4e9f-4627-999a-40d07380cd58"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77b5036c3c3f4d4b9aa89b478f3dabeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 1.0842 | train_acc: 0.3867 | test_loss: 0.9148 | test_acc: 0.5085\n",
            "Epoch: 2 | train_loss: 0.8721 | train_acc: 0.7734 | test_loss: 0.7976 | test_acc: 0.7434\n",
            "Epoch: 3 | train_loss: 0.7900 | train_acc: 0.7891 | test_loss: 0.7347 | test_acc: 0.7633\n",
            "Epoch: 4 | train_loss: 0.7275 | train_acc: 0.7539 | test_loss: 0.6570 | test_acc: 0.8968\n",
            "Epoch: 5 | train_loss: 0.6420 | train_acc: 0.7812 | test_loss: 0.6279 | test_acc: 0.9072\n",
            "[INFO] Total training time: 330.975 seconds\n"
          ]
        }
      ],
      "source": [
        "# Set the random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer \n",
        "start_time = timer()\n",
        "\n",
        "# Setup training and save the results\n",
        "model_0_results = engine.train(model=model_0,\n",
        "                       train_dataloader=train_dataloader,\n",
        "                       test_dataloader=test_dataloader,\n",
        "                       optimizer=optimizer,\n",
        "                       loss_fn=loss_fn,\n",
        "                       epochs=5,\n",
        "                       device=device)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFS4lE_IKyE_"
      },
      "source": [
        "### Make predictions on the entire test dataset with the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DwZuCluFu375"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1206a1a0fee54f019d69a8416547a0fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
              "        2, 2, 2])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Make predictions on the entire test dataset\n",
        "test_preds = []\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "    # Loop through the batches in the test dataloader\n",
        "    for X, y in tqdm(test_dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # Pass data through the model\n",
        "        test_logits = model_0(X)\n",
        "\n",
        "        # Convert the pred logits to pred probs\n",
        "        pred_probs = torch.softmax(test_logits, dim=1)\n",
        "\n",
        "        # Convert the pred probs into pred labels\n",
        "        pred_labels = torch.argmax(pred_probs, dim=1)\n",
        "\n",
        "        # Add the pred labels to test preds list\n",
        "        test_preds.append(pred_labels)\n",
        "\n",
        "# Concatenate the test preds and put them on the CPU\n",
        "test_preds = torch.cat(test_preds).cpu()\n",
        "test_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb2bQ1b5K2WP"
      },
      "source": [
        "### Make a confusion matrix with the test preds and the truth labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I2jpYAcM07s"
      },
      "source": [
        "Need the following libraries to make a confusion matrix:\n",
        "* torchmetrics - https://torchmetrics.readthedocs.io/en/stable/\n",
        "* mlxtend - http://rasbt.github.io/mlxtend/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcKYZGWuK2P8",
        "outputId": "88c33b26-0b76-42d7-8a27-fb3073b1fc3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _ConnectionBase.__del__ at 0x10f8f99e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/zowcool/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 132, in __del__\n",
            "    self._close()\n",
            "  File \"/Users/zowcool/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 360, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/zowcool/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
            "    reader_close()\n",
            "  File \"/Users/zowcool/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 177, in close\n",
            "    self._close()\n",
            "  File \"/Users/zowcool/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 360, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mlxtend version: 0.23.1\n"
          ]
        }
      ],
      "source": [
        "# See if torchmetrics exists, if not, install it\n",
        "try:\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n",
        "except:\n",
        "    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOYVew4xMxgI",
        "outputId": "d3b393b8-09c3-46f7-c799-2f91ee4d30e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.23.1\n"
          ]
        }
      ],
      "source": [
        "# Import mlxtend upgraded version\n",
        "import mlxtend \n",
        "print(mlxtend.__version__)\n",
        "assert int(mlxtend.__version__.split(\".\")[1]) >= 19 # should be version 0.19.0 or higher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_5LU9-5Xu7dP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_truth = torch.cat([y for X, y in test_dataloader])\n",
        "test_truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# Setup confusion matrix instance\n",
        "confmat = ConfusionMatrix(num_classes=len(class_names), task=\"multiclass\")\n",
        "confmat_tensor = confmat(preds=test_preds, \n",
        "                         target=test_truth)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "fig, ax = plot_confusion_matrix(\n",
        "    conf_mat = confmat_tensor.numpy(), # matplotlib like working with numpy\n",
        "    class_names = class_names,\n",
        "    figsize = (10, 7),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqlStPo-gbrF"
      },
      "source": [
        "## 2. Get the \"most wrong\" of the predictions on the test dataset and plot the 5 \"most wrong\" images. You can do this by:\n",
        "* Predicting across all of the test dataset, storing the labels and predicted probabilities.\n",
        "* Sort the predictions by *wrong prediction* and then *descending predicted probabilities*, this will give you the wrong predictions with the *highest* prediction probabilities, in other words, the \"most wrong\".\n",
        "* Plot the top 5 \"most wrong\" images, why do you think the model got these wrong?\n",
        "\n",
        "You'll want to:\n",
        "* Create a DataFrame with sample, label, prediction, pred prob\n",
        "* Sort DataFrame by correct (does label == prediction)\n",
        "* Sort DataFrame by pred prob (descending)\n",
        "* Plot the top 5 \"most wrong\" image predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHtMeYHuvDwy"
      },
      "outputs": [],
      "source": [
        "# Get all test data paths\n",
        "from pathlib import Path\n",
        "test_data_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "test_labels = [path.parent.stem for path in test_data_paths]\n",
        "\n",
        "# Create a function to return a list of dictionaries with sample, label, prediction, pred prob\n",
        "def pred_and_score(test_paths, model, transform, class_names, device):\n",
        "    test_pred_list = []\n",
        "    for path in tqdm(test_paths):\n",
        "        # Create empty dict to store info for each sample\n",
        "        pred_dict = {}\n",
        "\n",
        "        # Get sample path\n",
        "        pred_dict[\"image_path\"] = path\n",
        "\n",
        "        # Get class name\n",
        "        class_name = path.parent.stem\n",
        "        pred_dict[\"class_name\"] = class_name\n",
        "\n",
        "        # Get prediction and prediction probability\n",
        "        from PIL import Image\n",
        "        img = Image.open(path) # open image\n",
        "        transformed_image = transform(img).unsqueeze(0) # transform image and add batch dimension\n",
        "        model.eval()\n",
        "        with torch.inference_mode():\n",
        "            pred_logit = model(transformed_image.to(device))\n",
        "            pred_prob = torch.softmax(pred_logit, dim=1)\n",
        "            pred_label = torch.argmax(pred_prob, dim=1)\n",
        "            pred_class = class_names[pred_label.cpu()]\n",
        "\n",
        "            # Make sure things in the dictionary are back on the CPU\n",
        "            pred_dict[\"pred-\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IvuTskxgjaw"
      },
      "source": [
        "## 3. Predict on your own image of pizza/steak/sushi - how does the model go? What happens if you predict on an image that isn't pizza/steak/sushi?\n",
        "* Here you can get an image from a website like http://www.unsplash.com to try it out or you can upload your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C16glgVFglmG"
      },
      "outputs": [],
      "source": [
        "# TODO: Get an image of pizza/steak/sushi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clA_KmihVYyA"
      },
      "outputs": [],
      "source": [
        "# TODO: Get an image of not pizza/steak/sushi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzvi8GprgmJ0"
      },
      "source": [
        "## 4. Train the model from section 4  in notebook 06 part 3 for longer (10 epochs should do), what happens to the performance?\n",
        "\n",
        "* See the model in notebook 06 part 3 for reference: https://www.learnpytorch.io/06_pytorch_transfer_learning/#3-getting-a-pretrained-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIKg53Jna-Rt"
      },
      "outputs": [],
      "source": [
        "# TODO: Recreate a new model \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhGT9igPgoF5"
      },
      "outputs": [],
      "source": [
        "# TODO: Train the model for 10 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oRrWPZTgoqL"
      },
      "source": [
        "## 5. Train the model from section 4 above with more data, say 20% of the images from Food101 of Pizza, Steak and Sushi images.\n",
        "* You can find the [20% Pizza, Steak, Sushi dataset](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi_20_percent.zip) on the course GitHub. It was created with the notebook [`extras/04_custom_data_creation.ipynb`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxyMMnUbgvw2"
      },
      "source": [
        "### Get 20% data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_fdu5m2eKT9",
        "outputId": "121c61f3-f505-4302-b3b9-8b8bae5b5e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Did not find data/pizza_steak_sushi_20_percent directory, creating one...\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi 20% data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi_20_percent/train'),\n",
              " PosixPath('data/pizza_steak_sushi_20_percent/test'))"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi_20_percent\"\n",
        "image_data_zip_path = \"pizza_steak_sushi_20_percent.zip\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it... \n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / image_data_zip_path, \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / image_data_zip_path, \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi 20% data...\") \n",
        "        zip_ref.extractall(image_path)\n",
        "\n",
        "    # Remove .zip file\n",
        "    os.remove(data_path / image_data_zip_path)\n",
        "\n",
        "# Setup Dirs\n",
        "train_dir_20_percent = image_path / \"train\"\n",
        "test_dir_20_percent = image_path / \"test\"\n",
        "\n",
        "train_dir_20_percent, test_dir_20_percent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQj7eFdSe4Fv"
      },
      "source": [
        "### Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEG_k785e7Jw"
      },
      "outputs": [],
      "source": [
        "# Create a transforms pipeline\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82x7LnQJe7H5",
        "outputId": "342fd4e7-0656-495a-aee0-0d23be130438"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7f5ede28e390>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7f5ede28e210>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create training and testing DataLoader's as well as get a list of class names\n",
        "train_dataloader_20_percent, test_dataloader_20_percent, class_names = data_setup.create_dataloaders(train_dir=train_dir_20_percent,\n",
        "                                                                                                     test_dir=test_dir_20_percent,\n",
        "                                                                                                     transform=simple_transform, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                                                     batch_size=32) # set mini-batch size to 32\n",
        "\n",
        "train_dataloader_20_percent, test_dataloader_20_percent, class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qROl77sKfIOd"
      },
      "source": [
        "### Get a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHWNZ6yDvpR8"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqffJfOIfp3T"
      },
      "source": [
        "### Train a model with 20% of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXpYOYeTvp7a"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibj4UPjRgvly"
      },
      "source": [
        "## 6. Try a different model from [`torchvision.models`](https://pytorch.org/vision/stable/models.html) on the Pizza, Steak, Sushi data, how does this model perform?\n",
        "* You'll have to change the size of the classifier layer to suit our problem.\n",
        "* You may want to try an EfficientNet with a higher number than our B0, perhaps `torchvision.models.efficientnet_b2()`?\n",
        "  * **Note:** Depending on the model you use you will have to prepare/transform the data in a certain way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FQ8tL7El7eO"
      },
      "outputs": [],
      "source": [
        "# TODO "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNXgsMoZLpp/LR5qPnNG65Z",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "06_pytorch_transfer_learning_exercises.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06df3ad4b7454556a43b6d61640b12f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bdc7325c839439589a16c88876d6bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa41d239a3a4845904434d057476a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2678a567b0414e1d9cfbfc2ecf5ffd30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37424313e66f474da42cfe1b512f09df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc33539914a947ee89c271f10ea6a2bb",
            "placeholder": "",
            "style": "IPY_MODEL_6e03cb60fab94b7e92ce16c8178922dd",
            "value": "100%"
          }
        },
        "4a05e8d965124327a2329cf9e1eec984": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4827c6e36a1463fb0c82347f64230a2",
            "placeholder": "",
            "style": "IPY_MODEL_cea8f9c48bd8429998352a090173f537",
            "value": " 5/5 [00:31&lt;00:00,  5.81s/it]"
          }
        },
        "58fd00f6a9114192a4fa757c1f669bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d464254c31d4516899643112fa0e958",
            "max": 21444401,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06df3ad4b7454556a43b6d61640b12f8",
            "value": 21444401
          }
        },
        "5d464254c31d4516899643112fa0e958": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e03cb60fab94b7e92ce16c8178922dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e25b4bb0d254191a793696a0f4f00ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37424313e66f474da42cfe1b512f09df",
              "IPY_MODEL_58fd00f6a9114192a4fa757c1f669bff",
              "IPY_MODEL_f115ea4b5fad4bb1910fca49ed3da8a1"
            ],
            "layout": "IPY_MODEL_e8eba8e353e940ff9287929e41e4d656"
          }
        },
        "755366e3f75e44c2b7a79bce78d77d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce621be138a84f33b24c05b2d9cfd5f0",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fa41d239a3a4845904434d057476a75",
            "value": 5
          }
        },
        "873a483782894789bf0dee546a1b2d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88dea77f1bcf44ffb69654515ee34f54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae21171f17de45d895ab7a319dade609": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9c60d9c0aed49faa993fd865fb09174",
              "IPY_MODEL_755366e3f75e44c2b7a79bce78d77d11",
              "IPY_MODEL_4a05e8d965124327a2329cf9e1eec984"
            ],
            "layout": "IPY_MODEL_fe93ec079b384ac38a6f4d0e505431ff"
          }
        },
        "bc33539914a947ee89c271f10ea6a2bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce621be138a84f33b24c05b2d9cfd5f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea8f9c48bd8429998352a090173f537": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8eba8e353e940ff9287929e41e4d656": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f115ea4b5fad4bb1910fca49ed3da8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bdc7325c839439589a16c88876d6bd5",
            "placeholder": "",
            "style": "IPY_MODEL_873a483782894789bf0dee546a1b2d50",
            "value": " 20.5M/20.5M [00:00&lt;00:00, 61.8MB/s]"
          }
        },
        "f4827c6e36a1463fb0c82347f64230a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9c60d9c0aed49faa993fd865fb09174": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88dea77f1bcf44ffb69654515ee34f54",
            "placeholder": "",
            "style": "IPY_MODEL_2678a567b0414e1d9cfbfc2ecf5ffd30",
            "value": "100%"
          }
        },
        "fe93ec079b384ac38a6f4d0e505431ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
